# 第十周

## 运行结果

对于使用卷积神经网络训练的mnist数据集结果如下;

![运行结果](.\运行结果.png)

![运行结果2](.\运行结果2.PNG)

## 卷积的特性

通过卷积实现自动的特征提取，主要依赖卷积的如下几个特性：

#### 1.局部相关性

a.这点可以由卷积运算得知，感受野内的数值进行不同方式的运算最后取均值，相当于平均化了各个像素对于局部的影响。

b.卷积的层数越多，相当于不断叠加feature map,相应的最后一张feature map对应的第一幅图像中的感受野会变大。

c.对于存在局部相关性的数据，卷积都好用，是一个道理。

d.由a可知，即便是存在小范围的遮挡（噪声），由于卷积的滤波作用，可以减少影响。

#### 2.参数共享

#### 3.平移宽容

个人理解这是对应图像变换前后同样的特征都会激活神经元。

#### 4.缩放宽容

在一定程度的缩放范围内（25%），可以保持输入输出的基本不变。这个和3类似，可以理解结为对图像的仿射变换具有一定的容忍度。

#### 5.少许降维

卷积会造成降维![卷积降维后的形式](.\卷积降维后的形式.PNG)这个不言自明,直接上课程PPT截图。

#### 6.对输入的尺寸不做要求

图像大小就是影响同样stride的条件下，卷积核移动的次数，大小无所谓。

全连接的网络图像大像素多，w也就多，同样不会对网络的第二层及以后的结构造成影响。

## 卷积比全连接好的地方

1.卷积可以有效的使边缘角点等特征显现出来。

2.全连接层由于参数过多，会有许多无效的信息参与运算，运算慢相较于卷积取出噪声后的运算更容易过拟合，造成训练效果变差。